{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link: https://www.kaggle.com/optimo/tabnetmultitaskclassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.multitask import TabNetMultiTaskClassifier\n",
    "\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"lish-moa\"\n",
    "train = pd.read_csv(\"../data/train_features.csv\")\n",
    "train_targets = pd.read_csv('../data/train_targets_scored.csv')\n",
    "train_targets.drop(columns=[\"sig_id\"], inplace=True)\n",
    "test = pd.read_csv('../data/test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "if \"Set\" not in train.columns:\n",
    "    train[\"Set\"] = np.random.choice([\"train\", \"valid\"], p =[.8, .2], size=(train.shape[0],))\n",
    "\n",
    "train_indices = train[train.Set==\"train\"].index\n",
    "valid_indices = train[train.Set==\"valid\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sig_id     23814\n",
      "cp_type        2\n",
      "cp_time        3\n",
      "cp_dose        2\n",
      "g-0        14367\n",
      "           ...  \n",
      "c-96       14493\n",
      "c-97       14757\n",
      "c-98       14812\n",
      "c-99       14622\n",
      "Set            2\n",
      "Length: 877, dtype: int64 sig_id      object\n",
      "cp_type     object\n",
      "cp_time      int64\n",
      "cp_dose     object\n",
      "g-0        float64\n",
      "            ...   \n",
      "c-96       float64\n",
      "c-97       float64\n",
      "c-98       float64\n",
      "c-99       float64\n",
      "Set         object\n",
      "Length: 877, dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1415f93dc43b4fb79f40e6d2f843e9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=877.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sig_id 23814\n",
      "Column sig_id does not exist in test set\n",
      "cp_type 2\n",
      "cp_time 3\n",
      "cp_dose 2\n",
      "Set 2\n",
      "Column Set does not exist in test set\n",
      "\n",
      "['sig_id', 'cp_type', 'cp_time', 'cp_dose', 'Set'] {'sig_id': 23814, 'cp_type': 2, 'cp_time': 3, 'cp_dose': 2, 'Set': 2}\n"
     ]
    }
   ],
   "source": [
    "nunique = train.nunique()\n",
    "types = train.dtypes\n",
    "\n",
    "print(nunique, types)\n",
    "\n",
    "categorical_columns = []\n",
    "categorical_dims =  {}\n",
    "for col in tqdm(train.columns):\n",
    "    if types[col] == 'object' or nunique[col] < 200:\n",
    "        print(col, train[col].nunique())\n",
    "        l_enc = LabelEncoder()\n",
    "        train[col] = train[col].fillna(\"VV_likely\")\n",
    "        train[col] = l_enc.fit_transform(train[col].values)\n",
    "        try:\n",
    "            test[col] = test[col].fillna(\"VV_likely\")\n",
    "            test[col] = l_enc.transform(test[col].values)\n",
    "        except:\n",
    "            print(f\"Column {col} does not exist in test set\")\n",
    "        categorical_columns.append(col)\n",
    "        categorical_dims[col] = len(l_enc.classes_)\n",
    "    else:\n",
    "        training_mean = train.loc[train_indices, col].mean()\n",
    "        train.fillna(training_mean, inplace=True)\n",
    "        test.fillna(training_mean, inplace=True)\n",
    "        \n",
    "print(categorical_columns, categorical_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_feat = ['Set', 'sig_id'] # Let's not use splitting sets and sig_id\n",
    "\n",
    "features = [ col for col in train.columns if col not in unused_feat] \n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Set', 'sig_id']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unused_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
